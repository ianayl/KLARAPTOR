The {\em Parallel Random Access Machine}
(PRAM) model~\cite{DBLP:journals/siamcomp/StockmeyerV84,Gibbons:1989:MPP:72935.72953},
including models tailored to GPU code analysis
such as 
TMM~\cite{DBLP:journals/fgcs/MaAC14} and  MCM~\cite{DBLP:conf/parco/HaqueMX15}
analyze the performance of parallel programs at an abstract level.
More detailed GPU performance models are proposed such as MWP-CWP 
\cite{DBLP:conf/isca/HongK09,DBLP:conf/ppopp/SimDKV12}, which estimates the execution time of GPU kernels based on the profiling information of the kernels. 


In the context of improving {\cuda} program performance, other research groups have
used techniques such as loop transformation \cite{DBLP:conf/ics/BaskaranBKRRS08},
auto-tuning~\cite{grauer2012auto,Khan:2013:SAC:2400682.2400690,DBLP:books/daglib/p/SatoTKK10,DBLP:conf/icpp/KurzakTGAD19},
dynamic instrumentation~\cite{kistler2003continuous}, or
a combination of the latter two~\cite{song2015automated}.
%%
Auto-tuning techniques have achieved great results
in projects such as 
ATLAS~\cite{DBLP:conf/ppsc/WhaleyD99},
FFTW~\cite{DBLP:conf/icassp/FrigoJ98}, and
SPIRAL~\cite{DBLP:journals/ijhpca/PuschelMSXJPVJ04}
in which multiple kernel versions are generated 
\textit{off-line} and then applied and refined  \textit{on-line}
once the runtime parameters are known.
In contrast, our technique does not optimize the parallel code itself, 
only the program parameters controlling it.

Although much research has been devoted to compiler optimizations 
for kernel source code or PTX code, previous works such
as~\cite{DBLP:conf/cascon/ChenCKMX15} and~\cite{DBLP:journals/tjs/TorresGL13}
suggest that kernel launch
parameters (i.e. thread block configurations)
have a large impact on performance and must be considered
as a target for optimization.
%%
%%
In \cite{liu2009cross}, the authors present an input-adaptive GPU code
optimization framework G-ADAPT, which uses statistical learning to
find a relation between the input sizes and the thread block sizes.
\fixed{At linking time}{Marc: Why can't we be more precise?}, the framework predicts the best block size
for a given input size using the linear model obtained from compile
time.  This approach only considers the total size of the thread
blocks and not their configuration.  Meanwhile, the authors
of~\cite{DBLP:books/daglib/p/SatoTKK10} use a linear regression model
to predict optimal thread block configurations (that is, dimension
sizes and not just the total size). However, they assume kernel execution time
scales linearly with data size.
The authors in~\cite{DBLP:conf/icpp/LimNM17}
have also developed a method determining the best thread block configuration, 
but similarly, they assume execution time scales linearly with data size.
%the authors claim to have a static analysis method which does not
%require running the code for determining the best configuration for
%{\cuda} kernels. 
%Through static code analysis, IPC (instructions per clock-cycle)
%is estimated, however, 
%%They analyze the assembly code generated by
%%the {\texttt{NVCC}} compiler and estimate the IPC %(instruction per clock-cycle)
%%of each instruction, but,
%there is no analysis of memory access patterns, 
%\todo{and it is assumed that kernel execution time is proportional to 
%	the input problem size.}{Alex: I have softened the language this. It was once: 
%	The authors assume 
%	``the execution time of a {\cuda} program is proportional to the
%	input problem size $N$'' \cite[pp.527]{DBLP:conf/icpp/LimNM17}.
%	This may not be practical for some applications such as matrix
%	multiplication.}
%This is, obviously, a very strong assumption, and impractical
%for real world applications where even simple operations such as
%matrix multiplication are not proportional to their input size.
%Moreover, the paper only reports on 4 test-cases 
%(unlike a standard test suite such as PolyBench which includes 15 examples).
%%
%
%Moreover, only two benchmarks are provided.
%%
In~\cite{DBLP:conf/icpp/GarveyA15},
machine learning techniques are used in combination with auto-tuning
to search for optimal configurations of OpenCL kernels, but
their examples are limited to stencil computations. On the other hand, 
ISAAC~\cite{10.1145/3126908.3126939}, an auto-tuning framework, utilizes 
predictive modeling techniques and a regression model on input characteristics 
to generate optimized hardware and application-specific CUDA kernels from 
parameterized PTX code templates. However, its functionality is still restricted 
to matrix multiplication and convolution operations.
%% , but they note many important factors, 
%% namely, high-performing configurations are hard to find and there are very few of them.
%They suggest that the optimization space is
%large but most of them perform poorly. So they apply a
%machine learning model based on the data loading technique
%to pruning the configuration space as the first step. Then two alternative heuristics are used for grouping the remaining optimizations. 

